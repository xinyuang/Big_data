bin/spark-shell

List example:

scala> val rdd1 = sc.parallelize(Array(5,6,7,8,9,1,2,3))
rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:24

scala> val rdd2 = rdd1.map(_*2).sortBy(x=>x,true)
rdd2: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[6] at sortBy at <console>:26

scala> rdd2.collect
res0: Array[Int] = Array(2, 4, 6, 10, 12, 14, 16, 18)

scala> val rdd3 = rdd2.filter(_>10)
rdd3: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[7] at filter at <console>:28

scala> rdd3.collect
res1: Array[Int] = Array(12, 14, 16, 18)

scala> val rdd4 = sc.parallelize(List("a b c", "d e f","z x y"))
rdd4: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[8] at parallelize at <console>:24

scala> val rdd5 = rdd4.flatMap(_.split(" "))
rdd5: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[9] at flatMap at <console>:26

scala> rdd5.collect
res2: Array[String] = Array(a, b, c, d, e, f, z, x, y)

scala> val rdd6 = sc.parallelize(List(5,6,7,8,9,2,34))
rdd6: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[10] at parallelize at <console>:24

scala> val rdd7 = sc.parallelize(List(1,2,3,4,5,6,7))
rdd7: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[11] at parallelize at <console>:24

scala> val rdd8 = rdd6.union(rdd7).collect
rdd8: Array[Int] = Array(5, 6, 7, 8, 9, 2, 34, 1, 2, 3, 4, 5, 6, 7)

scala> val rdd9 = rdd6.intersection(rdd7).collect
rdd9: Array[Int] = Array(6, 7, 5, 2)

Key,Value exapmle:

scala> val rdd1 = sc.parallelize(List(("Tom",1000),("Jerry",3000),("Marry",2000)))
rdd1: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[1] at parallelize at <console>:24

scala> val rdd2 = sc.parallelize(List(("Mike",2000),("Jerry",1000),("Tom",3000)))
rdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[2] at parallelize at <console>:24

scala> val rdd3 = rdd1 union rdd2  
  or
scala> val rdd3 = rdd1.union(rdd2)
rdd3: org.apache.spark.rdd.RDD[(String, Int)] = UnionRDD[4] at union at <console>:28

scala> rdd3.collect
res1: Array[(String, Int)] = Array((Tom,1000), (Jerry,3000), (Marry,2000), (Mike,2000), (Jerry,1000), (Tom,3000))

scala> val rdd4 = rdd3.groupByKey.collect
rdd4: Array[(String, Iterable[Int])] = Array((Mike,CompactBuffer(2000)), (Marry,CompactBuffer(2000)), (Jerry,CompactBuffer(3000, 1000)), (Tom,CompactBuffer(1000, 3000)))

scala> val rdd5 = rdd1.cogroup(rdd2).collect
rdd5: Array[(String, (Iterable[Int], Iterable[Int]))] = Array((Mike,(CompactBuffer(),CompactBuffer(2000))), (Tom,(CompactBuffer(1000),CompactBuffer(3000))), (Marry,(CompactBuffer(2000),CompactBuffer())), (Jerry,(CompactBuffer(3000),CompactBuffer(1000))))

scala> val rdd6 = rdd3.reduceByKey(_+_).collect
rdd4: Array[(String, Int)] = Array((Mike,2000), (Marry,2000), (Jerry,4000), (Tom,4000))

scala> val rdd7 = rdd6.map(t=>(t._2,t._1)).sortByKey(false).map(t=>(t._2,t._1)).collect
rdd7: Array[(String, Int)] = Array((Jerry,4000), (Tom,4000), (Mike,2000), (Marry,2000))


