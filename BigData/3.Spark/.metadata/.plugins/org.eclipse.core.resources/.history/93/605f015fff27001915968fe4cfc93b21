package wordCount

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext

object myWordCount {
  def main(args: Array[String]): Unit = {
    val master = "local"
    val conf = new SparkConf().setAppName("myWordCount").setMaster(master)
    val sc = new SparkContext(conf)
    val result = sc.textFile("hdfs://bigdata111:9000/input/data.txt")
      .flatMap(_.split(" "))
      .map((_,1))
			.reduceByKey(_+_)
		result.foreach(println)
		sc.stop()
  }
}